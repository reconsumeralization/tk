import requests
from bs4 import BeautifulSoup


def fetch_sweep_issue(tracking_id):
    url = f"https://progress.sweep.dev/issues/{tracking_id}"
    response = requests.get(url)
    return response.text

def parse_sweep_issue(html):
    soup = BeautifulSoup(html, 'html.parser')
    # The exact implementation of this function will depend on the structure of the sweep issue pages.
    # For example, if the issue data is contained in a div with id 'issue-data', you could do:
    issue_data = soup.find(id='issue-data').text
    return issue_data

def aggregate_sweep_issues(tracking_ids):
    all_issue_data = []
    for tracking_id in tracking_ids:
        html = fetch_sweep_issue(tracking_id)
        issue_data = parse_sweep_issue(html)
        all_issue_data.append(issue_data)
    return all_issue_data

if __name__ == "__main__":
    tracking_ids = ['123', '456', '789']  # Replace with actual tracking_ids
    print(aggregate_sweep_issues(tracking_ids))
